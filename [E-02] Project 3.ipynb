{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82911060",
   "metadata": {},
   "source": [
    "# [E02] Project 3\n",
    "\n",
    "\n",
    "> **목차**\n",
    "===\n",
    " - 개요\n",
    " - 루브릭 평가기준\n",
    " - 용어 정리 및 모델 요약정리\n",
    " - Project - 1. 손글씨 분류\n",
    " - Project - 2. 와인 분류\n",
    " - Project - 3. 유방암 여부 진단\n",
    " - 참조\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325fbf1",
   "metadata": {},
   "source": [
    "> **개요**  \n",
    "===\n",
    "1. 어떤 지표가 해석에 주요한 점인지 파악할 것이다.\n",
    "2. 어떤 모델로 학습하는게 가장 우수한지 비교해볼 것이다.\n",
    "3. 각 프로젝트마다 오차행렬에서 recall과 precision 중 중점적으로 해석해야 될지를 정해야 한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce1d9a",
   "metadata": {},
   "source": [
    "> **루브릭 평가기준**\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea433e12",
   "metadata": {},
   "source": [
    "## 평가문항 \n",
    "\n",
    "1. 3가지 데이터 셋의 구성이 합리적으로 진행되었는가?\n",
    "2. 3가지 데이터 셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?\n",
    "3. 3가지 데이터 셋에 대해 모델의 평가지표가 적절히 선택되었는가?\n",
    "\n",
    "----\n",
    "## 상세기준\n",
    "\n",
    "1. Feature와 Label의 선정을 위한 데이터 분석과정이 체계적으로 전개됨\n",
    "2. 모델 학습 및 테스트가 정상적으로 수행되었음\n",
    "3. 평가지표 선택 및 이유 설명이 타당함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5b5f8",
   "metadata": {},
   "source": [
    "> **용어 정리 및 모델 요약정리**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9893ea",
   "metadata": {},
   "source": [
    "**지도학습**   \n",
    "\n",
    "정답이 있는 문제에 대해 학습하는 것을 의미한다.\n",
    "크게 분류해서 분류와 회귀로 나눠진다.\n",
    "\n",
    "---\n",
    "**분류**  \n",
    "입력받은 데이터를 특정 카테고리 중 하나로 분류해내는 문제\n",
    "Ex) 아이리스 품종 분류 문제\n",
    "\n",
    "---\n",
    "**회귀**  \n",
    "회귀는 입력받은 데이터에 따라 특정 필드의 수치를 맞히는 문제\n",
    "Ex) 집에대한 정보(평수, 위치, 층수) 등을 입력받아 가격을 추측하는 문제\n",
    "\n",
    "---\n",
    "**비지도 학습**\n",
    "\n",
    "타깃 데이터가 없어서 무엇을 예측한다기보단 입력데이터에서 어떤 특징을 찾는데 주로 이용된다.\n",
    "\n",
    "---\n",
    "**앙상블(Ensemble method)**  \n",
    "의견을 통합하거나 아ㅕ러가지 결과를 합치는 방식을 데이터 사이언스에서는 앙상블이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc515ad6",
   "metadata": {},
   "source": [
    "> **모델 요약 정리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8677ba",
   "metadata": {},
   "source": [
    "**[Decision Tree]**  \n",
    "의사결정나무 라고도 하며 분기에 따라 선택지가 나뉘는 모습이 나무를 거꾸로 담은 것과 같아서 이름 붙여졌다.  \n",
    "\n",
    "---\n",
    "장점\n",
    "+ 해석의 용이성 -> 쉽게 이해가 가능하다. \n",
    "+ 교호효과의 해석 -> 두개 이상의 변수가 결합하여 목표 변수에 어떻게 영향을 주는지 쉽게 알 수 있다.\n",
    "+ 비모수적 모형 -> 선형성, 정규성, 등분산성 등의 가정이 필요없다.\n",
    "\n",
    "---\n",
    "단점\n",
    "+ 비연속성 -> 연속형 변수를 비연속적으로 해석하기 때문에 경계점 부근에서 예측오류가 생길 수 있다.\n",
    "+ 선형성 or 주효과의 결여\n",
    "+ 비안정성 -> 분석용 자료에만 의존하므로 새로운 자료의 예측에서는 불안정할 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebc036",
   "metadata": {},
   "source": [
    "**[Random Forest]**\n",
    "\n",
    "수많은 의사결정트리가 모여서 만들어진 모델이다.\n",
    "\n",
    "---\n",
    "장점  \n",
    "+ Classification 및 Regression 문제에 모두 적용가능\n",
    "+ Missing value(결측치)를 다루기 쉬움\n",
    "+ 대용량 데이터 처리에 효과적\n",
    "+ 모델의 노이즈를 심화시키는 오버피팅 문제를 회피할 수 있다.\n",
    "+ Classification 모델에서 상대적으로 중요한 변수 선정 및 Ranking 가능\n",
    "\n",
    "---\n",
    "단점  \n",
    "+ 데이터 수가 많아지면 속도가 크게 느려진다.\n",
    "+ 결과에 대한 해석이 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942eb9ad",
   "metadata": {},
   "source": [
    "**[SVM(Support Vector Machine]**  \n",
    "\n",
    "Support Vector와 Hyperplane(초평면)을 이용해서 분류를 수행\n",
    "\n",
    "---\n",
    "**분류방법**  \n",
    "Decision Boundary와 Support Vector사이의 거리 값을 최대화 시켜서 분류 한다.\n",
    "\n",
    "---\n",
    "장점  \n",
    "+ 범주나 수치 예측 문제에 사용 가능\n",
    "+ 오류 데이터에 대한 영향이 없다.\n",
    "+ 과적합이 되는 경우가 적고 \n",
    "+ 신경망보다 사용하기 쉽다.\n",
    "\n",
    "---\n",
    "단점  \n",
    "+ 여러 개의 조합 테스트 필요\n",
    "+ 학습 속도가 느림\n",
    "+ 해석이 어렵고 복잡한 블랙박스 형태로 되어있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7629981",
   "metadata": {},
   "source": [
    "**[SGD Classifier]**  \n",
    "\n",
    "Stochastic Gradient Descent Classifier로 배치 크기가 1인 경사하강법 알고리즘이다.  \n",
    "데이터 셋에서 무작위로 균일하게 선택한 하나의 예를 의존하여 각 단계의 예측 경사를 계산한다.\n",
    "\n",
    "---\n",
    "장점  \n",
    "- 학습 속도가 빠르다.\n",
    "- 하나의 샘플만 메모리에 있으면 되기 때문에 큰 데이터 셋도 학습 가능\n",
    "\n",
    "---\n",
    "단점  \n",
    "- 샘플 선택이 확률적이기 때문에 배치 경사 하강법에 비해 불안정하다.\n",
    "- 반복이 충분하면 SGD가 효과적이지만 노이즈가 매우 심하다.\n",
    "- SGD의 여러 변형 함수의 최저점에 가까운 점을 찾을 가능성이 높지만 항상 보장되지는 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86de661",
   "metadata": {},
   "source": [
    "**[Logistic Regression]**  \n",
    "\n",
    "소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘이다.  \n",
    "다중 클래스 분류를 위한 로지스틱 회귀를 소프트 맥스 회귀라고도 한다.  \n",
    "\n",
    "---\n",
    "장점  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3680d3bc",
   "metadata": {},
   "source": [
    "> **Project - 1 손글씨 분류**\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a23039",
   "metadata": {},
   "source": [
    "> **1) 학습전 추론**\n",
    "-\n",
    "\n",
    "불러들인 데이터 값이 전처리가 필요할지 여부에 대해 정확도가 많이 떨어진다면 시행해야겠지만,  \n",
    "기존 데이터가 이미 가공된 데이터기 때문에 전처리 없이도 정확도에 큰 영향은 없을것이라 생각된다.\n",
    "\n",
    "손글씨 데이터는 숫자가 맞는지를 판별하는 데이터로 잘못 해석될 시 발생하는 영향이 미미하다.  \n",
    "때문에 오차행렬을 통한 분석은 필요하지 않다고 여겨진다.  \n",
    "\n",
    "가장 주의해야 될 점은 데이터값이 치우쳐져 있는지 해석해봐야 한다.  \n",
    "***why?***   \n",
    "데이터가 치우쳐져 있으면 오차행렬을 사용하지 않으려고 생각한 만큼 정확도 지표의 신뢰도가 떨어지기 때문이다.  \n",
    "결론적으로 **정확도**를 가장 중요한 데이터로 여기고 시험할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca941ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee38e60",
   "metadata": {},
   "source": [
    "> 2) **데이터 준비**  \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0567fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_digits # 손글씨 데이터 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report # 오차행렬을 위한 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정나무 import\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest import\n",
    "from sklearn import svm # svm import\n",
    "from sklearn.linear_model import SGDClassifier # sgd classifier import\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d6b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 데이터 준비\n",
    "digits = load_digits()  # 로드한 digits  digits에 넣기\n",
    "digits_data = digits.data # Feature Data 지정\n",
    "digit_label = digits.target # Label Data 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f74944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names) # 8*8 픽셀로 나눠진걸 볼 수 있다.\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e99d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digit_label, \n",
    "                                                    test_size=0.2, # 20% 시험 데이터 추출\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6bdfd",
   "metadata": {},
   "source": [
    "> **3) 다양한 모델로 학습**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a51d9b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        43\n",
      "           1       0.83      0.81      0.82        42\n",
      "           2       0.82      0.82      0.82        40\n",
      "           3       0.91      0.91      0.91        34\n",
      "           4       0.83      0.92      0.87        37\n",
      "           5       0.87      0.96      0.92        28\n",
      "           6       0.93      0.93      0.93        28\n",
      "           7       0.87      0.82      0.84        33\n",
      "           8       0.82      0.65      0.73        43\n",
      "           9       0.74      0.81      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c65f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.92      1.00      0.96        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.94      1.00      0.97        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       1.00      0.91      0.95        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.97      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X_train, y_train)\n",
    "y_pred = randomforest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a90e188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03133afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.92      0.86      0.89        42\n",
      "           2       0.95      1.00      0.98        40\n",
      "           3       0.94      0.91      0.93        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.90      0.88      0.89        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2087b215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter = 2500) # 그냥 코드로 돌렸을 시에 정답에 도달하기전에 종료되서 max iter를 늘려줬다.\n",
    "\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0ccb4",
   "metadata": {},
   "source": [
    "> **4) 결론**\n",
    "-\n",
    "\n",
    "## Data Base\n",
    "훈련 data : 80%  \n",
    "시험 data : 10% \n",
    "\n",
    "---\n",
    "## Decision Tree \n",
    "\n",
    "정확도 : 85%        \n",
    "\n",
    "---   \n",
    "## Random Forest\n",
    "\n",
    "정확도 : 95%\n",
    "\n",
    "---\n",
    "## SVM 채택\n",
    "\n",
    "정확도 : 99%\n",
    "\n",
    "---\n",
    "## SGD Classifier\n",
    "\n",
    "정확도 : 95%\n",
    "\n",
    "---\n",
    "## Logistic Regression\n",
    "\n",
    "정확도 : 95%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555828d",
   "metadata": {},
   "source": [
    "> **회고**\n",
    "-\n",
    "\n",
    "사전에 전처리의 필요성에 대해 생각해봤을때 가공된 데이터기 때문에 필요없을 것이라 예상한점은 맞았다.  \n",
    "데이터 값이 맞고 틀림에 따른 인과관계에 대한 관점 없이 정확도만으로 판단했을때 SVM 모델로 학습했을때 가장 우수한 모델이 나왔다.  \n",
    "그 외 나머지는 Decision Tree 를 제외하고는 95%이상의 값이 나왔는데, Random Forest 모델이 Decision Tree의 상위 버전인 만큼 정확도가  \n",
    "더 좋게 나옴을 볼 수 있었다.  \n",
    "\n",
    "결론적으로는 사전 예측때 그랬던 것처럼 정확도를 기준으로 판별했을 때 SVM이 가장 높았기 때문에  \n",
    "이 손글씨 분류에서는 SVM 모델이 가장 적합하다고 생각된다.\n",
    "\n",
    "---\n",
    "> **어려웠던 점**\n",
    "-\n",
    "\n",
    "Logistic Regression 에서 디폴트값으로 연산하면 계속해서 오류가 발생했다.  \n",
    "이유는 값에 가까이는 가도 도달하지 못한채로 연산이 종료 됐다.  \n",
    "이 문제를 해결하기 위해서 구글링을 통해서 max_iter 값을 늘려주면 된다는걸 깨달았고, \n",
    "값을 계속해서 올려주면서 적절한 반복횟수를 찾아 낼 수 있었다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b22618",
   "metadata": {},
   "source": [
    "> **Project -2 와인 분류**\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed37069",
   "metadata": {},
   "source": [
    "> **1) 학습전 추론**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781d6cb",
   "metadata": {},
   "source": [
    "Project - 1 에서도 그랬지만 CSV 파일은 정형 데이터기 때문에 별도의 전처리 작업이 없어도 정확도가 나옴을 알 수 있다.  \n",
    "와인을 세개로 분류하는 작업을 하는데 손글씨 분류 작업과 마찬가지로 어떤 특정 지표가 잘못 계산됨에 따라 치명적이지 않고,\n",
    "이진분류가 아니기때문에 오차행렬 분석은 시행하지 않는다.\n",
    "정확도를 가지고 모델의 성능을 파악할 예정이다.\n",
    "데이터의 양이 적고 3개의 클래스를 분류하는 것이기 때문에 많은 표본이 필요한 모델들은 정확도가 적게 나올것으로 예상되고  \n",
    "의사결정나무나 Random Forest 등이 좀 더 적합한 모델일 것으로 추측된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0b1a1",
   "metadata": {},
   "source": [
    "> **2) 데이터 준비**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476c287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_wine # 와인 데이터 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report # 오차행렬을 위한 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정나무 import\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest import\n",
    "from sklearn import svm # svm import\n",
    "from sklearn.linear_model import SGDClassifier # sgd classifier import\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668f1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 데이터 준비\n",
    "wine = load_wine()  # 로드한 wine데이터 wine에 넣기\n",
    "wine_data = wine.data # Feature Data 지정\n",
    "wine_label = wine.target # Label Data 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0658167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n",
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.target_names) # 총 세개로 나눠짐 ['class_0' 'class_1' 'class_2']\n",
    "print(wine.DESCR) # 와인에 관한 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af23019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.3,# 30% 시험 데이터 추출\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49828054",
   "metadata": {},
   "source": [
    "> **3) 다양한 모델로 학습**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ea97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        23\n",
      "           1       0.89      0.89      0.89        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.92      0.93      0.93        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c382986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        23\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.96      0.97      0.96        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X_train, y_train)\n",
    "y_pred = randomforest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d63cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81        23\n",
      "           1       0.60      0.83      0.70        18\n",
      "           2       0.40      0.31      0.35        13\n",
      "\n",
      "    accuracy                           0.67        54\n",
      "   macro avg       0.63      0.63      0.62        54\n",
      "weighted avg       0.68      0.67      0.66        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c1bdd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80        23\n",
      "           1       0.59      0.72      0.65        18\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.43      0.56      0.48        54\n",
      "weighted avg       0.49      0.65      0.56        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d0a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        23\n",
      "           1       0.89      0.94      0.92        18\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.94      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter = 2500) # 그냥 코드로 돌렸을 시에 정답에 도달하기전에 종료되서 max iter를 늘려줬다.\n",
    "\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385e040",
   "metadata": {},
   "source": [
    "> **4) 결론**\n",
    "-\n",
    "\n",
    "## Data Base\n",
    "훈련 data : 70%  \n",
    "시험 data : 30% \n",
    "\n",
    "---\n",
    "## Decision Tree \n",
    "\n",
    "정확도 : 93%        \n",
    "\n",
    "---   \n",
    "## Random Forest 채택\n",
    "\n",
    "정확도 : 98%\n",
    "\n",
    "---\n",
    "## SVM\n",
    "\n",
    "정확도 : 67%\n",
    "\n",
    "---\n",
    "## SGD Classifier\n",
    "\n",
    "정확도 : 57%\n",
    "\n",
    "---\n",
    "## Logistic Regression\n",
    "\n",
    "정확도 : 94%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19236441",
   "metadata": {},
   "source": [
    "> **회고**\n",
    "-\n",
    "\n",
    "손글씨 분류와는 다르게 훈련에 쓰일 데이터 양이 적어서 그런지 SVM이나 SGD Classifier등에서는 정확도가 아주 적게 나옴을 알 수 있다.\n",
    "처음에는 표본이 적기 때문에 9:1의 비율로 훈련데이터와 시험데이터를 나눴었는데 이렇게 분류하니깐 SGD Classifier에서 분류를 못하는 현상이 발생해서 훈련에 필요한 데이터량을 좀 더 추가 했다.\n",
    "적은 양의 데이터에서는 Random Forest가 아주 적합한 모델임을 알 수 있었고, 표본의 수를 늘리는게 정확도 계산에 중요한 역할을 한다는걸 깨달을 수 있었다.\n",
    "\n",
    "결론적으로는 와인 분류에서는 Random Forest 모델이 가장 적합하다고 생각된다.\n",
    "\n",
    "---\n",
    "> **어려웠던 점**\n",
    "-\n",
    "\n",
    "회고에도 썼지만 SGD Classifier가 시험 표본이 적을 경우에는 제대로 나눠지질 않아서 고민을 많이 하고 구글링을 하면서 공부했다.\n",
    "그 외에는 손글씨랑 거의 유사하기 때문에 어려운 점은 없었다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cafcf9",
   "metadata": {},
   "source": [
    "> **Project -3 유방암 여부 진단**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744f890",
   "metadata": {},
   "source": [
    "> **1) 학습전 추론**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea083a30",
   "metadata": {},
   "source": [
    "다른 두 프로젝트와 마찬가지로 가공된 CVS 파일 이기 때문에 별도의 전처리는 없이 훈련 및 시험을 하지만  \n",
    "다른 점은 암진단여부를 가리기 때문에 이진행렬이기도 하고 오진으로 인한 위험을 줄이기 위해 오차행렬분석도 같이 병행할 것이다.\n",
    "단순 정확도 추정만이 아니기 때문에 복합적으로 판단해야해서 좀 더 난이도가 있을 것으로 예상된다.\n",
    "\n",
    "오차행렬분석에서 암진단에 있어서 암환자인데 건강하다고 오진할 확률이 적을 때 이상적인 수치가 만들어질것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2adf628",
   "metadata": {},
   "source": [
    "> **2) 데이터 준비**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32190502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_breast_cancer # 유방암진단 데이터 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report # 오차행렬을 위한 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 의사결정나무 import\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest import\n",
    "from sklearn import svm # svm import\n",
    "from sklearn.linear_model import SGDClassifier # sgd classifier import\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3994469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 데이터 준비\n",
    "breast_cancer = load_breast_cancer()  # 로드한 유방암 진단 데이터 breast_cancer에 넣기\n",
    "breast_cancer_data = breast_cancer.data # Feature Data 지정\n",
    "breast_cancer_label = breast_cancer.target # Label Data 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf00b90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.target_names) # 두 개로 나눠짐 ['malignant' 'benign']\n",
    "print(breast_cancer.DESCR) # 유방암 진단에 관한 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "878cb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, \n",
    "                                                    breast_cancer_label, \n",
    "                                                    test_size=0.25,# 25% 시험 데이터 추출\n",
    "                                                    random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043b8db",
   "metadata": {},
   "source": [
    "> **3) 다양한 모델로 학습**\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8417ca0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.95      0.96      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "[[48  5]\n",
      " [ 4 86]]\n",
      "정밀도 : 0.9056603773584906\n",
      "재현율 : 0.3582089552238806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred)) # 오차행렬 분석을 위한 값 각각 TP,FN,FP,TN 이다. TP, TN이 클수록 좋다.\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]) # 정밀도\n",
    "recall =  conf_mat[0,0] / (conf_mat[1,1] + conf_mat[0,0]) # 재현율\n",
    "print(\"정밀도 : {}\\n재현율 : {}\\n\".format(precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b5f3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.95      0.96      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "[[48  5]\n",
      " [ 4 86]]\n",
      "정밀도 : 0.9056603773584906\n",
      "재현율 : 0.3582089552238806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X_train, y_train)\n",
    "y_pred = randomforest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred)) # 오차행렬 분석을 위한 값 각각 TP,FN,FP,TN 이다. TP, TN이 클수록 좋다.\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]) # 정밀도\n",
    "recall =  conf_mat[0,0] / (conf_mat[1,1] + conf_mat[0,0]) # 재현율\n",
    "print(\"정밀도 : {}\\n재현율 : {}\\n\".format(precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f1391bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.86        53\n",
      "           1       0.89      0.97      0.93        90\n",
      "\n",
      "    accuracy                           0.90       143\n",
      "   macro avg       0.91      0.88      0.89       143\n",
      "weighted avg       0.90      0.90      0.90       143\n",
      "\n",
      "[[42 11]\n",
      " [ 3 87]]\n",
      "정밀도 : 0.7924528301886793\n",
      "재현율 : 0.32558139534883723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) \n",
    "print(confusion_matrix(y_test, y_pred)) # 오차행렬 분석을 위한 값 각각 TP,FN,FP,TN 이다. TP, TN이 클수록 좋다.\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]) # 정밀도\n",
    "recall =  conf_mat[0,0] / (conf_mat[1,1] + conf_mat[0,0]) # 재현율\n",
    "print(\"정밀도 : {}\\n재현율 : {}\\n\".format(precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b38230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77        53\n",
      "           1       0.97      0.68      0.80        90\n",
      "\n",
      "    accuracy                           0.78       143\n",
      "   macro avg       0.80      0.82      0.78       143\n",
      "weighted avg       0.85      0.78      0.79       143\n",
      "\n",
      "[[51  2]\n",
      " [29 61]]\n",
      "정밀도 : 0.9622641509433962\n",
      "재현율 : 0.45535714285714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred)) # 오차행렬 분석을 위한 값 각각 TP,FN,FP,TN 이다. TP, TN이 클수록 좋다.\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]) # 정밀도\n",
    "recall =  conf_mat[0,0] / (conf_mat[1,1] + conf_mat[0,0]) # 재현율\n",
    "print(\"정밀도 : {}\\n재현율 : {}\\n\".format(precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dee3dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        53\n",
      "           1       0.96      0.97      0.96        90\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.95      0.95      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n",
      "[[49  4]\n",
      " [ 3 87]]\n",
      "정밀도 : 0.9245283018867925\n",
      "재현율 : 0.3602941176470588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter = 2500) # 그냥 코드로 돌렸을 시에 정답에 도달하기전에 종료되서 max iter를 늘려줬다.\n",
    "\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred)) # 오차행렬 분석을 위한 값 각각 TP,FN,FP,TN 이다. TP, TN이 클수록 좋다.\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]) # 정밀도\n",
    "recall =  conf_mat[0,0] / (conf_mat[1,1] + conf_mat[0,0]) # 재현율\n",
    "print(\"정밀도 : {}\\n재현율 : {}\\n\".format(precision,recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed3a63",
   "metadata": {},
   "source": [
    "> **4) 결론**\n",
    "-\n",
    "\n",
    "## Data Base\n",
    "훈련 data : 75%  \n",
    "시험 data : 25% \n",
    "\n",
    "---\n",
    "## Decision Tree 채택\n",
    "\n",
    "정확도 : 94%  \n",
    "정밀도 : 93%    \n",
    "재현율 : 37%  \n",
    "\n",
    "---   \n",
    "## Random Forest\n",
    "\n",
    "정확도 : 94%   \n",
    "정밀도 : 92%   \n",
    "재현율 : 36%   \n",
    "\n",
    "---\n",
    "## SVM \n",
    "\n",
    "정확도 : 90%  \n",
    "정밀도 : 79%   \n",
    "재현율 : 33%   \n",
    "\n",
    "---\n",
    "## SGD Classifier\n",
    "\n",
    "정확도 : 70% ~ 90%\n",
    "정밀도 : 70% ~ 100%\n",
    "재현율 : 33% ~ 53%  \n",
    "\n",
    "---\n",
    "## Logistic Regression \n",
    "\n",
    "정확도 : 95%  \n",
    "정밀도 : 92%  \n",
    "재현율 : 36%  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109eff0",
   "metadata": {},
   "source": [
    "> **회고**\n",
    "-\n",
    "\n",
    "가장 중요한 점은 양성인데 음성으로 판단 하는 경우가 적어야 되서 재현율(Recall)을 가장 중요하게 판단하고 그 다음으로 정밀도, 정확도 순으로 점수를 매겨서 채택했다. 의사 결정나무가 가장 간단한 로직을 가지고 있고 그 업그레이드 버전이 random forest라고 생각해서 고민을 했지만 시험 지표상으로 가장 중점적으로 봤던 재현율이 가장 높기도 하고 그 후에 정밀도도 높아서 가장 이상적인 모델로 결정했다.\n",
    "\n",
    "---\n",
    "> **어려웠던 점**\n",
    "-\n",
    "\n",
    "SGD Classifier는 매커니즘 자체가 확률로 만들어져있기 때문인지 몰라도 재현율이 때로는 가장 이상적으로 나와서 고민을 했지만  \n",
    "수치 변동이 너무 커서 의사결정나무랑 고민하는데에 시간을 많이 소비했다. 좀 더 표본이 많다면 이렇게까지 변동이 크지 않았을텐데 하는 아쉬움이 남았다.  \n",
    "\n",
    "재현율이 시험 표본이 적었을 때 너무 적게 나오는 현상이 발생해서 적절한 값을 유도하면서 고민을 했고, 현재도 재현율이 너무 낮게 나와서 이게 맞게 됐는지 걱정스럽다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593deb3",
   "metadata": {},
   "source": [
    "> 참조\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0d092",
   "metadata": {},
   "source": [
    "1) 의사결정나무 장단점 - https://dreamlog.tistory.com/576  \n",
    "2) Random Forest 장단점 - https://wooono.tistory.com/115  /  https://jjeongil.tistory.com/908  \n",
    "3) SVM 장단점 https://muzukphysics.tistory.com/entry/ML-8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-SVM-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%9E%A5%EB%8B%A8%EC%A0%90-Support-Vector-Machine  \n",
    "4) 경사하강법 장단점 : https://velog.io/@arittung/DeepLearningStudyDay8  \n",
    "5) SGD Classifier 오류 해결 - https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi  \n",
    "6) 오차행렬분석 - https://kimdingko-world.tistory.com/173\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
