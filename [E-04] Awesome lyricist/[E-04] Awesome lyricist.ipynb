{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7d4ba2",
   "metadata": {},
   "source": [
    "# [E-04] Awesome lyricist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b11a2",
   "metadata": {},
   "source": [
    "> 목차\n",
    "-\n",
    "\n",
    "\n",
    "**1. 개요**  \n",
    "    \n",
    "    1.1 프로젝트 과정 및 목표  \n",
    "    1.2 예상되는 문제점  \n",
    "    1.3 용어  \n",
    "\n",
    "**2. 루브릭 평가기준**  \n",
    "\n",
    "**3. Project**\n",
    "    \n",
    "    3.1 데이터 준비하기    \n",
    "    3.2 데이터 전처리  \n",
    "    3.3 데이터 분리 및 학습시키기  \n",
    "    3.4 데이터 테스트\n",
    "**4. 회고**\n",
    "    \n",
    "    4.1 결과 평가  \n",
    "    4.2 어려웠던 점\n",
    "    4.3 참조\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9086fd",
   "metadata": {},
   "source": [
    "---\n",
    "> **1. 개요**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d7c0e",
   "metadata": {},
   "source": [
    "> **1.1 프로젝트 과정 및 목표**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a904d16",
   "metadata": {},
   "source": [
    "프로젝트의 과정은   \n",
    "1. 데이터 준비  \n",
    "2. 데이터 전처리\n",
    "3. 데이터 분리 및 학습시키기\n",
    "4. 데이터 테스트\n",
    "의 과정으로 이뤄진다.\n",
    "\n",
    "목표는 자연스러운 말이 출력이 되는걸로 우선적으로 잡았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47767a1a",
   "metadata": {},
   "source": [
    "> **1.2 예상되는 문제점**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48b394",
   "metadata": {},
   "source": [
    "+ NLP를 처음으로 접해서 코드를 이해하는데 어려움이 있을 것 같다.\n",
    "+ 학습하는데 걸리는 시간이 길어서 프로젝트 시간이 길어질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92659b",
   "metadata": {},
   "source": [
    "> **1.3 용어**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b886524",
   "metadata": {},
   "source": [
    "+ **순환 신경망(RNN)**\n",
    ": 시계열 데이터와 같이 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 인공 신경망\n",
    "+ **언어모델(Language Model)**\n",
    ": n−1개의 단어 시퀀스가 주어졌을 때, n번째 단어 w으로 무엇이 올지를 예측하는 확률 모델  \n",
    "+ **토큰화(Tokenization)**\n",
    ": 자연어 처리에서 크롤링 등으로 얻어낸 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)하는 일을 하게 됩니다. 이번에는 그 중에서도 토큰화에 대해서 학습합니다.  \n",
    "주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 합니다.\n",
    "+ **소스문장(Source Sentence)**\n",
    ": 모델의 입력이 되는 문장\n",
    "+ **타겟문장(Target Sentence)**\n",
    ": 모델의 출력 문장\n",
    "+ **텐서(Tensor)**\n",
    ": 텐서란 매우 수학적인 개념으로 데이터의 배열이라고 볼 수 있습니다. 텐서의 Rank는 간단히 말해서 몇 차원 배열인가를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21bb95",
   "metadata": {},
   "source": [
    "---\n",
    "> **2. 루브릭 평가기준**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc50c8",
   "metadata": {},
   "source": [
    "|평가문항 | 상세기준|\n",
    "|:---------|:---------|\n",
    "|1.가사 텍스트 생성 모델이 정상적으로 동작하는가? | 텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?|\n",
    "|2.데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가? | 특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?|\n",
    "|3.텍스트 생성모델이 안정적으로 학습되었는가?| 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eb754",
   "metadata": {},
   "source": [
    "---\n",
    "> **3. Project**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ab3ab",
   "metadata": {},
   "source": [
    "> 3.1 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f25bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob # 파일 읽어오기가 용이함\n",
    "import os, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24df86b",
   "metadata": {},
   "source": [
    "> 3.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c4e7bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n",
      "You saw her bathing on the roof\n",
      "Her beauty and the moonlight overthrew her\n",
      "She tied you\n",
      "To a kitchen chair\n",
      "She broke your throne, and she cut your hair\n",
      "And from your lips she drew the Hallelujah Hallelujah\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 15: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b166b701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    tmp = preprocess_sentence(sentence)\n",
    "    if len(tmp.split()) > 15: continue\n",
    "    corpus.append(tmp)\n",
    "    \n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541f9a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2967 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  118 ...    0    0    0]\n",
      " [   2  258  194 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fbe44359a90>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 \n",
    "import keras\n",
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post',maxlen = 15)  \n",
    "    \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823aacee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n",
      "11 : it\n",
      "12 : me\n",
      "13 : my\n",
      "14 : in\n",
      "15 : that\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 15: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e633427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d24ed",
   "metadata": {},
   "source": [
    "> 3.3 데이터 분리 및 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab1b8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                    tgt_input, \n",
    "                                                    test_size=0.2, # 전체의 20프로를 테스트 데이터로 사용함을 의미\n",
    "                                                    random_state=32) # 랜덤성을 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee259ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124810, 14)\n",
      "Target Train: (124810, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4a067",
   "metadata": {},
   "source": [
    "> 3.4 데이터 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf59483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d65bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512 # 워드 벡터의 차원수 단어가 추상적으로 표현되는 크기\n",
    "hidden_size = 2048 # 모델에 얼마나 많은 일꾼을 둘것인가?\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e77435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [-4.45797807e-04,  5.43098897e-04, -2.60865083e-04, ...,\n",
       "          4.16130089e-04,  3.76105279e-04, -3.94352188e-04],\n",
       "        [-5.39327273e-04,  4.22886660e-04,  2.55806499e-05, ...,\n",
       "          2.74052087e-04,  2.85774120e-04, -4.18458192e-04],\n",
       "        ...,\n",
       "        [ 3.18504218e-03,  2.59923586e-03, -3.83088039e-03, ...,\n",
       "          7.61765870e-04, -2.38400674e-03,  1.69440333e-04],\n",
       "        [ 3.55065032e-03,  2.85611395e-03, -4.59420495e-03, ...,\n",
       "          8.45399220e-04, -2.73591117e-03,  3.21258587e-04],\n",
       "        [ 3.84523254e-03,  3.03917797e-03, -5.28183999e-03, ...,\n",
       "          8.85773217e-04, -3.03919264e-03,  4.34380054e-04]],\n",
       "\n",
       "       [[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [-6.18144870e-04, -7.49558676e-05, -1.73080771e-04, ...,\n",
       "          8.96457408e-04,  9.73096176e-05, -4.55729954e-04],\n",
       "        [-1.06612267e-03, -3.31716787e-04, -3.72289127e-04, ...,\n",
       "          9.61136422e-04,  1.65519406e-04, -7.08234322e-04],\n",
       "        ...,\n",
       "        [ 2.09989434e-04,  5.82474400e-04,  1.16230838e-03, ...,\n",
       "          3.12135118e-04, -7.61903881e-04, -1.01803802e-04],\n",
       "        [ 7.63055752e-04,  1.02617603e-03,  3.64441454e-04, ...,\n",
       "          4.66174301e-04, -7.86625489e-04,  1.39852564e-04],\n",
       "        [ 1.35646074e-03,  1.47204089e-03, -5.82943787e-04, ...,\n",
       "          6.42694125e-04, -9.34162410e-04,  3.82116501e-04]],\n",
       "\n",
       "       [[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [-5.79210231e-04,  3.98203352e-04, -2.50008161e-04, ...,\n",
       "          1.76324742e-04,  8.56222687e-05, -4.16094495e-04],\n",
       "        [-4.47139551e-04,  3.13742086e-04, -2.67730240e-04, ...,\n",
       "          1.66547456e-04,  1.85925615e-04, -4.44976671e-04],\n",
       "        ...,\n",
       "        [ 7.50028761e-04,  6.43508392e-04,  1.06644502e-03, ...,\n",
       "          6.54779607e-04, -2.31728540e-04, -2.08744037e-04],\n",
       "        [ 1.02534506e-03,  9.13905969e-04,  5.89361938e-04, ...,\n",
       "          6.36492681e-04, -9.75537841e-05, -2.48315366e-04],\n",
       "        [ 1.45877735e-03,  1.30231841e-03, -1.18743519e-04, ...,\n",
       "          6.97375042e-04, -2.43498886e-04, -1.52838140e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [-6.98086922e-04,  2.70363118e-04, -3.45742068e-04, ...,\n",
       "          1.83873010e-04,  5.24209463e-05, -5.32292237e-04],\n",
       "        [-9.46957851e-04, -6.46760309e-05, -2.47112213e-04, ...,\n",
       "          3.19977931e-04, -1.99833448e-04, -7.34636036e-04],\n",
       "        ...,\n",
       "        [ 9.26251407e-04, -3.09242721e-04,  4.03951592e-04, ...,\n",
       "          9.04462300e-04,  1.32501358e-03, -1.40830292e-03],\n",
       "        [ 1.34385575e-03,  1.25167964e-04, -3.12869932e-04, ...,\n",
       "          1.06063730e-03,  9.30522045e-04, -1.03073858e-03],\n",
       "        [ 1.77120254e-03,  5.97271486e-04, -1.16768014e-03, ...,\n",
       "          1.19560736e-03,  4.56475827e-04, -6.33598305e-04]],\n",
       "\n",
       "       [[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [ 6.05474670e-05,  2.35219573e-04, -6.00702333e-05, ...,\n",
       "          4.55063884e-04, -1.30788067e-05, -1.93198313e-04],\n",
       "        [ 9.46208165e-05,  2.58889952e-04,  2.23090727e-04, ...,\n",
       "          6.46200671e-04,  4.14799433e-05,  5.44737413e-05],\n",
       "        ...,\n",
       "        [ 2.98989820e-03,  1.87217409e-03,  1.46832003e-03, ...,\n",
       "          1.03488856e-04,  8.43925154e-05, -3.00292479e-04],\n",
       "        [ 3.19933868e-03,  2.40165507e-03,  7.05591287e-04, ...,\n",
       "          2.06408236e-04, -2.66697665e-04, -9.10300369e-05],\n",
       "        [ 3.43408785e-03,  2.88485456e-03, -2.47032760e-04, ...,\n",
       "          3.48035275e-04, -7.09754473e-04,  1.53723187e-04]],\n",
       "\n",
       "       [[-3.09162890e-04,  2.44220835e-04, -1.60413358e-04, ...,\n",
       "          2.63404305e-04, -3.50302253e-06, -2.67830183e-04],\n",
       "        [-2.14091007e-04,  2.28095349e-04, -1.92827560e-04, ...,\n",
       "          4.59806994e-04,  5.40667788e-05, -3.21895699e-04],\n",
       "        [-1.37772528e-04, -2.16299042e-04, -1.27685751e-04, ...,\n",
       "          2.72570644e-04, -1.70761283e-04, -6.81198610e-04],\n",
       "        ...,\n",
       "        [ 7.36610731e-04, -1.23727880e-03,  6.18494989e-04, ...,\n",
       "         -1.80271058e-03,  3.66897555e-04,  6.75318355e-04],\n",
       "        [ 5.94202429e-04, -9.40014725e-04,  5.74718055e-04, ...,\n",
       "         -2.06315448e-03,  7.12989655e-04,  3.38968559e-04],\n",
       "        [ 8.21468304e-04, -2.71797064e-04,  1.52834880e-04, ...,\n",
       "         -2.01109494e-03,  7.27173581e-04,  2.79516098e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae1eece",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 255s 515ms/step - loss: 3.3164 - val_loss: 2.9475\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 259s 532ms/step - loss: 2.7831 - val_loss: 2.7033\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 279s 572ms/step - loss: 2.4944 - val_loss: 2.5253\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 260s 534ms/step - loss: 2.2104 - val_loss: 2.3879\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 260s 534ms/step - loss: 1.9363 - val_loss: 2.2845\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 260s 533ms/step - loss: 1.6839 - val_loss: 2.2074\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 260s 533ms/step - loss: 1.4648 - val_loss: 2.1621\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 260s 534ms/step - loss: 1.2872 - val_loss: 2.1410\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 260s 533ms/step - loss: 1.1525 - val_loss: 2.1469\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 260s 533ms/step - loss: 1.0634 - val_loss: 2.1606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbda003fbb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset,\n",
    "                                      epochs=10,\n",
    "                                      batch_size=256,\n",
    "                                      validation_data=(enc_val, dec_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50e415b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i love you <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가하기\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated\n",
    "\n",
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940d4a3",
   "metadata": {},
   "source": [
    "> **4. 회고**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf5bca",
   "metadata": {},
   "source": [
    "> 4.1 결과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535918d5",
   "metadata": {},
   "source": [
    "i love you, i love you 라는 엄청 로맨틱한 글이 나와서 기분이 굉장히 좋았습니다.   \n",
    "+ val_loss를 낮추는 과정을 좀 더 세밀하게 여러번 시도했었는데 그래서 결과가 좋게 나왔다고 생각합니다.  \n",
    "+ 데이터의 전처리가 잘되서 모델이 잘 나왔다고 생각합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c99767",
   "metadata": {},
   "source": [
    "> 4.2 어려웠던 점"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "097de757",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05a359",
   "metadata": {},
   "source": [
    "val_loss를 2.2 이하로 맞추기 위해서   \n",
    "+ embedding_size     \n",
    "+ hidden_size   \n",
    "\n",
    "하이퍼 파라미터를 각각 512, 2048로 조정한 결과 2.16 까지 떨어뜨릴 수 있었습니다.  \n",
    "값들을 증가시킬때마다 시간이 엄청 길어지지만 서서히 val_loss가 감소함을 알 수 있었습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb572a4",
   "metadata": {},
   "source": [
    "> 4.3  참조\n",
    "\n",
    "Val_loss 를 구하기 위해 참조 했습니다.  \n",
    "https://www.tensorflow.org/tutorials/keras/overfit_and_underfit?hl=ko"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
